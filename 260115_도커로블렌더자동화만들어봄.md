# TIL – n8n 기반 AI 자동화 Blender 조작 실험 (Docker · Headless · 실패 기록)

이번에 시도한 건 **n8n을 오케스트레이터로 사용해 LLM이 Blender를 자동으로 조작하는 파이프라인**을 만드는 실험이었다.
단순한 스크립트 실행이 아니라, “AI가 에셋을 만든다”는 환상을 실제 시스템으로 밀어붙여보는 게 목적이었다.

## 1. Docker로 모든 걸 한 컨테이너에 밀어 넣은 이유

가장 먼저 부딪힌 건 환경 문제였다.

* Blender는 로컬 GUI 의존성이 강하고
* LLM은 별도 런타임과 의존성을 요구하고
* n8n은 또 자기만의 실행 환경을 원한다

이걸 로컬에서 느슨하게 연결하면 재현성이 깨진다.
그래서 **Blender + Python + n8n + LLM API 클라이언트**를 전부 **하나의 Docker 컨테이너**에 넣었다.

이 선택은 꽤 좋았다.

* Blender를 CLI 모드로 안정적으로 실행 가능
* n8n 워크플로우 → Python → Blender 실행 흐름이 명확해짐
* “지금 이 에셋은 어떤 상태에서 만들어졌는가”를 컨테이너 단위로 고정 가능

특히 Blender를 아래 형태로 다루는 순간,
“아, 이게 자동화가 되는 영역이구나”라는 감각이 왔다.

```bash
blender -b template.blend -P generate_asset.py -- --params xxx
```

GUI 없는 **완전 헤드리스(headless)** 상태에서
.blend 파일이 열리고 → 메시가 생성되고 → 수정되고 → export 되는 걸 로그로만 확인하는 경험은 꽤 인상적이었다.

## 2. Headless Blender 조작에서 느낀 현실감

헤드리스 Blender는 생각보다 “기계” 같았다.

* 메시 생성
* 모디파이어 적용
* 머티리얼 세팅
* FBX / GLB export

이 모든 건 **정확히 명령한 것만 한다**.
눈치도 없고, 맥락도 없다.

사람이 Blender에서 작업할 때는:

* “이 실루엣 좀 이상한데?”
* “이 엣지는 너무 날카롭다”
* “이 비율은 캐릭터용이 아니다”

같은 판단을 계속한다.

하지만 headless Blender에서는
그 모든 게 **수치와 파라미터의 조합 문제**로 환원된다.

이 지점에서 LLM을 투입했다.

## 3. LLM + n8n 조합은 ‘제어’까지는 잘 된다

n8n을 통해 다음 구조를 만들었다.

* 프롬프트 입력
* LLM이 Blender 조작용 파라미터 / Python 코드 생성
* n8n이 그 코드를 실행
* 결과물 export 후 다음 스텝으로 전달

이 흐름 자체는 꽤 그럴듯했다.

* 메시 생성 로직을 바꾸고
* subdivision 단계를 조절하고
* 랜덤 시드를 다르게 주고

“AI가 에셋을 만든다”는 데모 수준까지는 충분히 간다.

문제는 **품질**이었다.

## 4. 순수 LLM 파라미터 조작의 한계

여기서 프로젝트의 한계가 명확해졌다.

LLM은 다음은 잘한다.

* 구조를 설명한다
* 절차를 나눈다
* 합리적인 것처럼 보이는 수치를 제안한다

하지만 못 하는 게 있다.

* **시각적 결과를 기준으로 미세 조정**
* “이건 틀렸고, 이건 맞다”라는 감각적 판정
* 반복을 통한 스타일 수렴

결과적으로 생성되는 에셋은:

* 기술적으로는 맞지만
* 미적으로는 애매하고
* 실사용 기준에서는 “조금 부족한” 상태에 머문다

반복을 돌릴수록 개선되기보다는
오히려 **랜덤한 변주를 계속 만드는 느낌**에 가까웠다.

이 시점에서 결론이 났다.

> LLM은 Blender를 **조작할 수는 있지만**
> Blender로 **잘 만들지는 못한다**

## 5. 그래서 이 프로젝트를 포기했다

이 실험은 “연결이 안 돼서” 실패한 게 아니다.

* Docker 구성은 안정적이었고
* headless Blender 제어도 문제없었고
* n8n + LLM 파이프라인도 잘 동작했다

하지만 **순수 자동화만으로 고퀄리티 3D 에셋을 만든다는 목표**가 틀렸다는 게 분명해졌다.

사람의 작업에서 가장 중요한 병목은:

* 파라미터 조작이 아니라
* 시각적 판단과 즉각적인 피드백 루프였다.

그래서 이 프로젝트는 여기서 종료.

다음에 다시 접근한다면,

* LLM은 “에셋 생성자”가 아니라
* **초기 초안 생성 + 보조 도구**로만 사용하고
* 최종 품질 판단은 인간이 맡는 구조가 될 것이다.

## 오늘의 교훈

자동화에서 제일 중요한 건
“어디까지 자동화가 가능한가”가 아니라
“품질의 병목이 어디에 있는가를 직접 확인해보는 것”이다.

이번 실험은 실패했지만,
그 병목을 아주 명확하게 보여준 실험이었다.
